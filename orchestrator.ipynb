{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a3ea11-4161-4e5b-937b-e873350dbd63",
   "metadata": {},
   "source": [
    "![Author](https://img.shields.io/badge/Author-Soufiane%20AAZIZI-brightgreen)\n",
    "[![Medium](https://img.shields.io/badge/Medium-Follow%20Me-blue)](https://medium.com/@aazizi.soufiane)\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Follow%20Me-lightgrey)](https://github.com/aazizisoufiane)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect%20with%20Me-informational)](https://www.linkedin.com/in/soufiane-aazizi-phd-a502829/)\n",
    "\n",
    "---\n",
    "# Streamlining Machine Learning Model Deployment with CI/CD and MLOps\n",
    "\n",
    "In today's ever-evolving landscape of data science and machine learning, proficiency in managing and deploying machine learning models has transitioned from a desirable skill to an absolute necessity. Aspiring data scientists are no longer solely responsible for building sophisticated models; they are also expected to seamlessly integrate these models into real-world applications. This is where the convergence of Continuous Integration and Continuous Deployment (CI/CD) and Machine Learning Operations (MLOps) takes center stage.\n",
    "\n",
    "In this Jupyter Notebook, we embark on an exciting journey into the realm of CI/CD and MLOps. Our goal is to demystify these crucial concepts and underscore their significance for emerging data scientists. Through hands-on exploration, we will delve into a project that harnesses the power of Amazon SageMaker and AWS Step Functions to simplify the entire process of data preprocessing, model training, and deployment. This project serves as an invaluable stepping stone for data scientists eager to acquire essential CI/CD and MLOps skills, further enhancing their appeal in today's competitive job market.\n",
    "\n",
    "Join us on this educational journey as we unlock the potential of CI/CD and MLOps in the context of machine learning, empowering you to take your data science expertise to the next level.\n",
    "## \n",
    "\n",
    "## Table of Contents\n",
    "- [Installing Required Packages](#Installing)\n",
    "- [Imports](#imports)\n",
    "- [Initialization](#initialization)\n",
    "- [Data Preprocessing Step](#data-preprocessing)\n",
    "- [Model Training and Evaluation Configuration ](#model-training)\n",
    "- [Model Deployment Configuration Â¶](#Endpoint-config) \n",
    "- [Workflow Creation and Configuration](#Create-WorkFlow)\n",
    "- [Workflow Execution](#Execute-WorkFlow) \n",
    "- [Model Inference](#prediction) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd671d1b-d8b7-494d-b290-f9239e92e1e5",
   "metadata": {},
   "source": [
    "### Installing Required Packages <a class=\"anchor\" id=\"Installin\"></a>\n",
    "Before we begin, let's make sure we have all the necessary Python packages installed. You can run the following command to install any missing packages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ff4f0-699f-4a40-afff-11d31cd2558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563bbbe-7aeb-4529-9c09-4e0eaac5487e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install stepfunctions  omegaconf  nb-black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb0890-69ae-4af5-947f-6e48f25d2c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b56c75-5533-4a16-9c70-4a5d82d0cdc1",
   "metadata": {},
   "source": [
    "### Auto-formatting and Auto-Reloading Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f622768-c2c0-4f7c-b677-8bb5472facd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ca0cf-6094-4eb0-9c65-2f66e76cfe51",
   "metadata": {},
   "source": [
    "## Imports <a class=\"anchor\" id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2ab76-fc14-44d3-a82e-188becf9045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "import stepfunctions\n",
    "from config import config\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from stepfunctions import steps\n",
    "from botocore.config import Config\n",
    "from stepfunctions.inputs import ExecutionInput\n",
    "from stepfunctions.workflow import Workflow\n",
    "from stepfunctions.steps import (\n",
    "    Chain,\n",
    "    ChoiceRule,\n",
    "    ModelStep,\n",
    "    ProcessingStep,\n",
    "    TrainingStep,\n",
    "    TransformStep,\n",
    "    Parallel,\n",
    ")\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d153b22d-44f2-44a4-8bb2-3ada1fb31f58",
   "metadata": {},
   "source": [
    "# Initialization <a class=\"anchor\" id=\"initialization\"></a>\n",
    "- Set up environment, load data, and configure settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa27b79-9698-4a7e-8a7d-33c8be438f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load environment variables from a .env file\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# Retrieve the SageMaker workflow execution role from environment variables\n",
    "workflow_execution_role = os.getenv(\"SAGEMAKER_WORKFLOW_ROLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86499857-9ef3-4363-b14a-697d5dfaa021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution_input = ExecutionInput(\n",
    "    schema={\n",
    "        \"JobName\": str,\n",
    "        \"PreprocessingJobName\": str,\n",
    "        \"TrainingJobName\": str,\n",
    "        \"ModelName\": str,\n",
    "        \"EndpointName\": str,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af7aeda-0940-4a7a-9743-c6f8b0f6f70f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a Fail state for handling SageMaker processing job failures\n",
    "failed_state_sagemaker_processing_failure = stepfunctions.steps.states.Fail(\n",
    "    \"ML Workflow failed\", cause=\"SageMakerProcessingJobFailed\"\n",
    ")\n",
    "\n",
    "# Define a Catch state for capturing specific errors and transitioning to the Fail state\n",
    "catch_state_processing = stepfunctions.steps.states.Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=failed_state_sagemaker_processing_failure,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac8a494-9a86-4a1f-a894-74a887f327fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "failed_state_sagemaker_training_failure = stepfunctions.steps.states.Fail(\n",
    "    \"ML Training failed\", cause=\"SageMakerTrainingJobFailed\"\n",
    ")\n",
    "\n",
    "catch_state_training = stepfunctions.steps.states.Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=failed_state_sagemaker_training_failure,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8de80-7977-44e7-bf4f-1143700120d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "failed_state_sagemaker_training_failure = stepfunctions.steps.states.Fail(\n",
    "    \"ML Save Model failed\", cause=\"SageMakerSaveModelJobFailed\"\n",
    ")\n",
    "\n",
    "catch_state_save_model = stepfunctions.steps.states.Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=failed_state_sagemaker_training_failure,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21237b-cdfb-4151-b373-2f38948ad55f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "failed_state_sagemaker_inference_failure = stepfunctions.steps.states.Fail(\n",
    "    \"ML Inference failed\", cause=\"SageMakerInferenceFailed\"\n",
    ")\n",
    "\n",
    "catch_state_inference = stepfunctions.steps.states.Catch(\n",
    "    error_equals=[\"States.TaskFailed\"],\n",
    "    next_step=failed_state_sagemaker_inference_failure,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88812830-a13c-4a4c-a696-1c47daa060f9",
   "metadata": {},
   "source": [
    "### Sagemaker Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe0313-9a1d-4e37-8de1-f4d3b5ab4248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a SageMaker Boto3 client with custom configuration\n",
    "sm_boto = boto3.client(\n",
    "    \"sagemaker\",\n",
    "    config=Config(connect_timeout=5, read_timeout=60, retries={\"max_attempts\": 60}),\n",
    ")\n",
    "\n",
    "# Initialize a SageMaker session using the custom Boto3 client\n",
    "sagemaker_session = sagemaker.Session(sagemaker_client=sm_boto)\n",
    "\n",
    "# Retrieve the AWS region from the SageMaker session\n",
    "region = sagemaker_session.boto_session.region_name\n",
    "\n",
    "# Get the execution role required for SageMaker operations\n",
    "role = get_execution_role()\n",
    "\n",
    "# Retrieve configuration values for the S3 bucket and prefix\n",
    "bucket = config.s3.bucket\n",
    "prefix = config.s3.prefix\n",
    "s3_bucket_base_uri = config.s3.s3_bucket_base_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c1f9f-bf65-4814-bf9d-ca6e61936b28",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d025535-cab2-4ee3-ad4c-29eab922705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_name(jobname):\n",
    "    \"\"\"\n",
    "    Generate a unique job name for an Amazon SageMaker job based on a given 'jobname' and current timestamp.\n",
    "\n",
    "    Args:\n",
    "        jobname (str): A descriptive name for the job.\n",
    "\n",
    "    Returns:\n",
    "        str: A unique job name incorporating the 'jobname' and timestamp.\n",
    "    \"\"\"\n",
    "    return f\"MultiLabelClassification-{jobname}--{time.strftime('%Y%m%d%H%M%S', time.gmtime())}\"\n",
    "\n",
    "\n",
    "def upload_code(bucket_name, prefix_name, script_location):\n",
    "    \"\"\"\n",
    "    Upload code or script to an Amazon S3 bucket for use in SageMaker.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket where the code will be uploaded.\n",
    "        prefix_name (str): The prefix or directory within the S3 bucket where the code will be stored.\n",
    "        script_location (str): The local path to the code or script file.\n",
    "\n",
    "    Returns:\n",
    "        str: The S3 URI of the uploaded code.\n",
    "    \"\"\"\n",
    "    return sagemaker_session.upload_data(\n",
    "        script_location,\n",
    "        bucket=bucket_name,\n",
    "        key_prefix=f\"{prefix_name}/{script_location}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c87036-d633-4c75-afa8-004eadb062ec",
   "metadata": {},
   "source": [
    "# Data Preprocessing Step <a class=\"anchor\" id=\"data-preprocessing\"></a>\n",
    "\n",
    "In this section of the notebook, our focus shifts towards the preparation and definition of a SageMaker processing step that is responsible for data preprocessing. Data preprocessing plays a pivotal role in any machine learning workflow as it encompasses the tasks of cleaning, transforming, and organizing raw data into a format that is suitable for model training.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Preprocessing Step Name**: We initiate this process by generating a descriptive name for the preprocessing step, which includes a timestamp. This unique identifier aids in tracking and managing this step within the workflow.\n",
    "\n",
    "2. **SKLearnProcessor Configuration**: We define a function called `sklearn_processor` that is responsible for creating an instance of the SageMaker SKLearnProcessor. This processor is a fundamental component of SageMaker, allowing us to run data preprocessing jobs using scikit-learn scripts. The configuration includes essential details such as the framework version, the IAM role required for job execution, the instance type for computation, and the number of instances.\n",
    "\n",
    "3. **Processing Step**: Here, we proceed to define the actual SageMaker processing step dedicated to data preprocessing. This step represents the execution of the preprocessing job within our workflow and includes the following key elements:\n",
    "   - `preprocessing_step_name`: The name generated earlier for this step.\n",
    "   - `processor`: An instance of the SKLearnProcessor, created using the `sklearn_processor` function.\n",
    "   - `job_name`: The name of the SageMaker processing job, extracted from an `execution_input` dictionary. It serves as a crucial identifier for tracking job progress.\n",
    "   - `inputs`: Configuration specifying the location of input data for preprocessing.\n",
    "   - `outputs`: Configuration indicating where the preprocessed data will be stored.\n",
    "   - `container_entrypoint`: The entry point for the processing job's container, specifying the script to be executed.\n",
    "   - `container_arguments`: Additional arguments passed to the processing container, which may include parameters like the train-test split ratio.\n",
    "\n",
    "The primary objective of this section is to establish a SageMaker processing step tailored to handle data preprocessing tasks within the broader machine learning workflow. By configuring various aspects, we ensure that the data undergoes proper preprocessing and is ready for subsequent stages of model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df644c-8bba-4bb0-b17d-27f967020f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the location of the preprocessing script within the project\n",
    "PREPROCESSING_SCRIPT_LOCATION = \"preprocess/code\"\n",
    "\n",
    "# Create the output path for preprocessing results using the S3 bucket base URI and prefix\n",
    "output_preprocess = \"{}/{}\".format(s3_bucket_base_uri, config.s3.prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dacf17-bc63-405d-9683-e98f3292e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the preprocessing script to an S3 location and get the S3 URI\n",
    "input_code_preprocess = sagemaker_session.upload_data(\n",
    "    PREPROCESSING_SCRIPT_LOCATION,\n",
    "    bucket=bucket,\n",
    "    key_prefix=f\"{prefix}/{PREPROCESSING_SCRIPT_LOCATION}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c6f63-af60-4450-974c-62c365544589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of ProcessingInput objects for the preprocessing job\n",
    "inputs_preprocess = [\n",
    "    ProcessingInput(\n",
    "        source=f\"{config.s3.s3_bucket_base_uri}/{config.s3.input}\",\n",
    "        destination=\"/opt/ml/processing/input\",\n",
    "        input_name=\"input-data\",\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=input_code_preprocess,\n",
    "        destination=\"/opt/ml/processing/input/code\",\n",
    "        input_name=\"code\",\n",
    "    ),\n",
    "    ProcessingInput(\n",
    "        source=f\"s3://{bucket}/{prefix}/{PREPROCESSING_SCRIPT_LOCATION}/config\",\n",
    "        destination=\"/opt/ml/processing/input/config\",\n",
    "        input_name=\"code-config\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417c9fb1-c3c1-48ad-8ea1-ba0b01afe00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of ProcessingOutput objects for the preprocessing job\n",
    "outputs_preprocess = [\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/train\",\n",
    "        destination=output_preprocess,\n",
    "        output_name=\"train_data\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/test\",\n",
    "        destination=output_preprocess,\n",
    "        output_name=\"test_data\",\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        source=\"/opt/ml/processing/labels\",\n",
    "        destination=output_preprocess,\n",
    "        output_name=\"labels_data\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596d16f-4467-4572-ac0c-26ef6c7d1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a descriptive name for the preprocessing step, including a timestamp.\n",
    "preprocessing_step_name = f\"Multilabel Classification - Preprocessing Step {time.strftime('%Y%m%d%H%M%S', time.gmtime())}\"\n",
    "\n",
    "\n",
    "# Define an Amazon SageMaker SKLearnProcessor with custom settings.\n",
    "def sklearn_processor(instance_type=\"ml.m5.xlarge\"):\n",
    "    \"\"\"\n",
    "    Create an SKLearnProcessor instance for Amazon SageMaker processing jobs.\n",
    "\n",
    "    Args:\n",
    "        instance_type (str): The Amazon SageMaker instance type for processing jobs.\n",
    "\n",
    "    Returns:\n",
    "        sagemaker.processing.SKLearnProcessor: An instance of the SKLearnProcessor.\n",
    "    \"\"\"\n",
    "    return SKLearnProcessor(\n",
    "        framework_version=\"1.2-1\",\n",
    "        role=role,  # Ensure the 'role' variable is defined and appropriate.\n",
    "        instance_type=instance_type,\n",
    "        instance_count=1,\n",
    "        # max_runtime_in_seconds=1200,  # Uncomment and customize if needed.\n",
    "    )\n",
    "\n",
    "\n",
    "# Define the SageMaker processing step for data preprocessing.\n",
    "processing_step = ProcessingStep(\n",
    "    preprocessing_step_name,\n",
    "    processor=sklearn_processor(),\n",
    "    job_name=execution_input[\"PreprocessingJobName\"],\n",
    "    inputs=inputs_preprocess,  # Define your input data configuration here.\n",
    "    outputs=outputs_preprocess,  # Define your output data configuration here.\n",
    "    container_entrypoint=[\"python3\", \"/opt/ml/processing/input/code/run.py\"],\n",
    "    container_arguments=[\n",
    "        \"--train-test-split-ratio\",\n",
    "        \"0.2\",\n",
    "    ],  # Uncomment and customize if needed.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516e8f40-942f-4b2f-841c-7ed582e69df8",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation Configuration <a class=\"anchor\" id=\"model-training\"></a>\n",
    "\n",
    "In this section, we configure various components essential for the model training and evaluation phase of our machine learning workflow.\n",
    "\n",
    "### Metric Definitions\n",
    "To assess the performance of our trained model, we define a list of metric definitions. These metrics serve as key indicators of the model's quality and effectiveness during evaluation. The metrics include metrics like loss, accuracy, F1 score, ROC (Receiver Operating Characteristic), ROC AUC (Area Under the Curve), precision, recall, runtime, samples per second, and epoch. These metrics will be computed and tracked during model training.\n",
    "\n",
    "### Instance Volume Configuration\n",
    "Different Amazon SageMaker instance types come with varying storage capacities. To ensure that our model training jobs have adequate storage space, we define an `instance_volume` configuration. This mapping specifies the instance type and the associated volume size, ensuring that the chosen instance type has sufficient storage capacity for the training process.\n",
    "\n",
    "### Training Parameters\n",
    "We set various training parameters necessary for configuring the HuggingFace estimator, which includes:\n",
    "- `epochs`: The number of training epochs.\n",
    "- `train-batch-size`: The batch size for training.\n",
    "- `eval_steps`: The number of evaluation steps.\n",
    "- `instance_type`: The SageMaker instance type to use for training.\n",
    "- `volume_size`: The volume size for the SageMaker instance.\n",
    "\n",
    "### Preprocessed Data Output Configuration\n",
    "Before moving forward, we retrieve the output configuration from the previous preprocessing step. This configuration contains information about the locations where preprocessed data is stored. Specifically, we identify the S3 URIs for preprocessed training, test, and labels data.\n",
    "\n",
    "### Model Estimator Generation\n",
    "We define a function called `generate_estimator()` responsible for creating the HuggingFace estimator. The estimator is configured with parameters such as the model name, number of epochs, batch size, output directory for checkpoints, evaluation steps, instance type, and other necessary details. This estimator serves as the foundation for model training.\n",
    "\n",
    "### Data Preparation\n",
    "We define another function named `generate_data()` that prepares the data for model training. This function specifies the paths to preprocessed training, test, and labels data and creates a dictionary specifying the data sources and content types.\n",
    "\n",
    "### Training Step Generation\n",
    "With the groundwork laid, we use the `generate_training_step()` function to create a SageMaker TrainingStep in our Step Functions workflow. This step includes essential information such as the job name, estimator, data sources, and other configurations. It represents the process of training our machine learning model.\n",
    "\n",
    "### Model Deployment Step\n",
    "Finally, we create a ModelStep named \"Save model\" that saves the trained model. This step uses the model obtained from the training step, specifies the model name, and defines the SageMaker instance type for model deployment.\n",
    "\n",
    "These configurations and steps prepare us for the subsequent phases of our machine learning workflow, including model training and evaluation, and model deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab56e2c-483f-480a-ad88-d55d858ae7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a list of metric definitions for model evaluation\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_accuracy\", \"Regex\": \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_f1\", \"Regex\": \"'eval_f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_roc\", \"Regex\": \"'eval_roc': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_roc_auc\", \"Regex\": \"'eval_roc_auc': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_precision\", \"Regex\": \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_recall\", \"Regex\": \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\"Name\": \"eval_runtime\", \"Regex\": \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {\n",
    "        \"Name\": \"eval_samples_per_second\",\n",
    "        \"Regex\": \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\",\n",
    "    },\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "]\n",
    "\n",
    "# Define instance volume configurations based on instance type\n",
    "instance_volume = {\n",
    "    \"ml.g4dn.16xlarge\": 900,\n",
    "    \"ml.g4dn.8xlarge\": 500,\n",
    "    \"ml.g4dn.4xlarge\": 225,\n",
    "    \"ml.g4dn.2xlarge\": 225,\n",
    "    \"ml.g4dn.xlarge\": 125,\n",
    "}\n",
    "\n",
    "# Define training parameters such as epochs, batch size, evaluation steps, instance type, and volume size\n",
    "params = {\n",
    "    \"epochs\": 1,\n",
    "    \"train-batch-size\": 8,\n",
    "    \"eval_steps\": 1,\n",
    "    \"instance_type\": \"ml.g4dn.4xlarge\",\n",
    "    \"volume_size\": 125,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9525ac67-1762-46d6-a9e7-57ed9acf7d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the ProcessingOutputConfig from the processing step's parameters\n",
    "output_config = processing_step.fields[\"parameters\"][\"ProcessingOutputConfig\"]\n",
    "\n",
    "# Initialize variables to store the S3 URIs for preprocessed data\n",
    "preprocessed_training_data = None\n",
    "preprocessed_test_data = None\n",
    "preprocessed_labels_data = None\n",
    "\n",
    "# Iterate through the list of outputs in the ProcessingOutputConfig\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    if output[\"OutputName\"] == \"train_data\":\n",
    "        # Set the S3 URI for preprocessed training data\n",
    "        preprocessed_training_data = os.path.join(\n",
    "            output[\"S3Output\"][\"S3Uri\"], \"train.csv\"\n",
    "        )\n",
    "    if output[\"OutputName\"] == \"test_data\":\n",
    "        # Set the S3 URI for preprocessed test data\n",
    "        preprocessed_test_data = os.path.join(output[\"S3Output\"][\"S3Uri\"], \"test.csv\")\n",
    "    if output[\"OutputName\"] == \"labels_data\":\n",
    "        # Set the S3 URI for preprocessed labels data\n",
    "        preprocessed_labels_data = os.path.join(\n",
    "            output[\"S3Output\"][\"S3Uri\"], \"labels.csv\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b79911d-61bc-4920-9757-78e07d858362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_estimator():\n",
    "    # Define the S3 URIs for checkpoints and training jobs\n",
    "    checkpoint_s3_uri = f\"s3://{config.s3.bucket}/{config.s3.prefix}/checkpoints\"\n",
    "    output_path = f\"s3://{config.s3.bucket}/{config.s3.prefix}/training_jobs\"\n",
    "\n",
    "    # Define hyperparameters for the HuggingFace estimator\n",
    "    hyperparameters = {\n",
    "        \"model_name\": \"distilbert-base-uncased\",\n",
    "        \"epochs\": params[\"epochs\"],\n",
    "        \"train-batch-size\": params[\"train-batch-size\"],\n",
    "        \"output_dir\": checkpoint_s3_uri,  # Use the checkpoint S3 URI for output\n",
    "        \"eval_steps\": params[\"eval_steps\"],\n",
    "    }\n",
    "\n",
    "    # Create and configure the HuggingFace estimator for SageMaker\n",
    "    return HuggingFace(\n",
    "        entry_point=\"train.py\",  # Entry point script for training\n",
    "        source_dir=\"train/code\",  # Source directory containing training code\n",
    "        output_path=f\"{output_path}/\",  # Output path for storing model artifacts\n",
    "        code_location=output_path,\n",
    "        role=role,  # SageMaker execution role\n",
    "        base_job_name=f\"multi-label-classification\",  # Base job name for SageMaker job\n",
    "        checkpoint_s3_uri=checkpoint_s3_uri,  # Specify the checkpoint input path\n",
    "        instance_type=params[\"instance_type\"],  # SageMaker instance type for training\n",
    "        instance_count=1,  # Number of training instances\n",
    "        transformers_version=\"4.6\",\n",
    "        pytorch_version=\"1.7\",\n",
    "        py_version=\"py36\",\n",
    "        hyperparameters=hyperparameters,  # Hyperparameters for training\n",
    "        metric_definitions=metric_definitions,  # Metric definitions for evaluation\n",
    "        volume_size=instance_volume[params[\"instance_type\"]],  # Instance volume size\n",
    "        sagemaker_session=sagemaker_session,  # SageMaker session\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46d298-80ce-4bc8-aa36-dd8468413b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data():\n",
    "    # Define the paths to preprocessed training, test, and labels data\n",
    "    train_path = preprocessed_training_data\n",
    "    test_path = preprocessed_test_data\n",
    "    labels_path = preprocessed_labels_data\n",
    "\n",
    "    # Create a dictionary specifying the training data sources and content types\n",
    "    data = {\n",
    "        \"train\": sagemaker.TrainingInput(train_path, content_type=\"text/libsvm\"),\n",
    "        \"test\": sagemaker.TrainingInput(test_path, content_type=\"text/libsvm\"),\n",
    "        \"labels\": sagemaker.TrainingInput(labels_path, content_type=\"text/libsvm\"),\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_training_step(instance=\"ml.g4dn.2xlarge\"):\n",
    "    # Generate a unique job name based on the current timestamp\n",
    "    jobname = (\n",
    "        f\"multi-label-classification--{time.strftime('%Y%m%d%H%M%S', time.gmtime())}\"\n",
    "    )\n",
    "\n",
    "    # Create a TrainingStep in the Step Functions workflow\n",
    "    training_step = steps.TrainingStep(\n",
    "        f\"Trainning -- instance {instance}\",  # Step name\n",
    "        estimator=generate_estimator(),  # Use the HuggingFace estimator\n",
    "        data=generate_data(),  # Specify training data sources\n",
    "        job_name=jobname,  # Job name for SageMaker training job\n",
    "        wait_for_completion=True,  # Wait for training job to complete\n",
    "    )\n",
    "\n",
    "    return training_step, jobname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e3dd0f-7b37-4246-96e6-7fce507434fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a SageMaker TrainingStep using the 'generate_training_step' function\n",
    "training_step, training_job_name = generate_training_step(params[\"instance_type\"])\n",
    "\n",
    "# Create a ModelStep to save the trained model\n",
    "model_step = steps.ModelStep(\n",
    "    \"Save model\",  # Step name\n",
    "    model=training_step.get_expected_model(),  # Use the model from the training step\n",
    "    model_name=training_job_name,  # Specify the model name\n",
    "    instance_type=params[\n",
    "        \"instance_type\"\n",
    "    ],  # SageMaker instance type for model deployment\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c4b03-7804-46cb-a9ee-2f72c9eb6dd7",
   "metadata": {},
   "source": [
    "\n",
    "# Model Deployment Configuration <a class=\"anchor\" id=\"Endpoint-config\"></a>\n",
    "\n",
    "In this section, we configure the deployment of our trained machine learning model as a SageMaker endpoint, making it accessible for inference and predictions.\n",
    "\n",
    "### Endpoint Configuration Step\n",
    "We begin by defining an `EndpointConfigStep` named \"Create Endpoint Config.\" This step is responsible for creating an endpoint configuration that specifies the deployment details for our trained model. The key configurations include:\n",
    "- `endpoint_config_name`: The name for the endpoint configuration, which is set to the `training_job_name` from the training step. This ensures consistency between the model and endpoint configurations.\n",
    "- `model_name`: The name of the model to associate with this endpoint configuration, also set to the `training_job_name`.\n",
    "- `initial_instance_count`: The initial number of instances (1 in this case) for the endpoint.\n",
    "- `instance_type`: The SageMaker instance type to use for the endpoint (e.g., \"ml.m5.large\").\n",
    "\n",
    "### Endpoint Step\n",
    "Following the creation of the endpoint configuration, we define an `EndpointStep` named \"Create Endpoint.\" This step is responsible for the actual deployment of the model as an endpoint. Key configurations for this step include:\n",
    "- `endpoint_name`: The name of the endpoint, which is set to the `training_job_name`. This ensures a consistent naming convention.\n",
    "- `endpoint_config_name`: The name of the endpoint configuration, which is also set to the `training_job_name`.\n",
    "\n",
    "These two steps together facilitate the deployment of our trained machine learning model as an accessible SageMaker endpoint, ready to serve predictions and inferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42d7f2-9113-4416-bc27-0fd4901e5d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define an Endpoint Configuration Step to create an endpoint configuration.\n",
    "endpoint_config_step = steps.EndpointConfigStep(\n",
    "    \"Create Endpoint Config\",\n",
    "    endpoint_config_name=training_job_name,  # Use the training job name as the endpoint config name\n",
    "    model_name=training_job_name,  # Use the training job name as the model name\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    ")\n",
    "\n",
    "# Define an Endpoint Step to create the actual endpoint.\n",
    "endpoint_step = steps.EndpointStep(\n",
    "    \"Create Endpoint\",\n",
    "    endpoint_name=training_job_name,  # Use the training job name as the endpoint name\n",
    "    endpoint_config_name=training_job_name,  # Use the training job name as the endpoint config name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5204556-bdff-4a94-82f5-e28fa9ebd470",
   "metadata": {},
   "source": [
    "# Workflow Creation and Configuration <a class=\"anchor\" id=\"Create-WorkFlow\"></a>\n",
    "\n",
    "In this section, we create and configure a Step Functions workflow named 'MlOpsWorkflow' to orchestrate the entire machine learning operations (MLOps) process, including data preprocessing, training, model deployment, and endpoint setup. The workflow is defined by chaining various steps together to ensure a streamlined execution.\n",
    "\n",
    "### Catch States for Error Handling\n",
    "Before defining the workflow, we set up catch states for error handling. These catch states are designed to handle failures that might occur during different stages of the workflow. The catch states include:\n",
    "- `catch_state_processing`: Handling errors related to data processing.\n",
    "- `catch_state_training`: Handling errors during model training.\n",
    "- `catch_state_save_model`: Handling errors when saving the trained model.\n",
    "- `catch_state_inference`: Handling errors during model inference and predictions.\n",
    "\n",
    "### Workflow Graph Definition\n",
    "The core of the workflow is defined in a `workflow_graph` by chaining together multiple steps. These steps include:\n",
    "- `processing_step`: Responsible for data preprocessing.\n",
    "- `training_step`: Initiates model training.\n",
    "- `model_step`: Saves the trained model.\n",
    "- `endpoint_config_step`: Creates an endpoint configuration.\n",
    "- `endpoint_step`: Deploys the model as an endpoint.\n",
    "\n",
    "The steps are executed sequentially, ensuring that each step is completed successfully before moving on to the next. The catch states are attached to these steps to handle any potential failures gracefully.\n",
    "\n",
    "### Workflow Creation\n",
    "After defining the workflow graph and configuring error handling, we create the Step Functions workflow named 'MlOpsWorkflow.' The configuration for this workflow includes:\n",
    "- `name`: The name of the workflow, set to \"MlOpsWorkflow\" for clarity.\n",
    "- `definition`: The workflow graph we defined earlier, serving as the workflow's definition.\n",
    "- `role`: The execution role required for the workflow, specified as `workflow_execution_role`.\n",
    "\n",
    "Once created, this workflow can be executed to automate the entire MLOps pipeline, ensuring a smooth and reliable process for training and deploying machine learning models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03c77f-59f5-47c4-80c1-75ed7bbdddcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from stepfunctions.workflow import Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2ffd0-4d6d-4ee4-ab1c-c0a5b9b4902d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add catch states to handle failures for processing, training, and model steps\n",
    "processing_step.add_catch(catch_state_processing)\n",
    "training_step.add_catch(catch_state_training)\n",
    "model_step.add_catch(catch_state_save_model)\n",
    "endpoint_step.add_catch(catch_state_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c51994-2615-48b7-9c58-1e029305a623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a workflow graph by chaining the processing, training, model, endpoint config, and endpoint steps\n",
    "workflow_graph = Chain(\n",
    "    [processing_step, training_step, model_step, endpoint_config_step, endpoint_step]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc48d4-80bb-4171-9a5e-08d169750efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Step Functions workflow named 'MlOpsWorkflow' using the defined graph and execution role\n",
    "branching_workflow = Workflow(\n",
    "    name=job_name(\"MlOpsWorkflow\"),  # Specify the workflow name\n",
    "    definition=workflow_graph,  # Use the workflow graph as the definition\n",
    "    role=workflow_execution_role,  # Specify the execution role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70003f-ba1b-4f51-9f0d-d1baea8fdff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Step Functions workflow\n",
    "branching_workflow.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c876ca-b66a-4d43-a43e-03435582cb10",
   "metadata": {},
   "source": [
    "# Workflow Execution <a class=\"anchor\" id=\"Execute-WorkFlow\"></a>\n",
    "\n",
    "In this section, we execute the previously defined Step Functions workflow named 'MlOpsWorkflow.' The execution is initiated with specific input parameters that customize the execution process. These parameters include:\n",
    "- `\"PreprocessingJobName\"`: A parameter specifying the job name for the data preprocessing step.\n",
    "- `\"TrainingJobName\"`: A parameter specifying the job name for the model training step.\n",
    "\n",
    "### Initiating Workflow Execution\n",
    "To kick off the workflow execution, we use the `execute` method on the `branching_workflow` object. This method starts the execution of the workflow with the provided input parameters. The input parameters allow us to configure and customize the execution for each run. Additional input parameters can be included as needed to further tailor the workflow execution.\n",
    "\n",
    "### Retrieving Workflow Output\n",
    "After initiating the workflow execution, we retrieve the output of the execution. Note that the `get_output` method is called with the `wait=False` parameter, indicating that we do not want to block the execution and wait for its completion. This is particularly useful for non-blocking executions, and it allows us to continue with other tasks or processes while monitoring the progress of the workflow.\n",
    "\n",
    "The output of the execution can include various pieces of information, such as the status of the workflow, step execution details, and any error messages encountered during execution.\n",
    "\n",
    "By following this approach, you can automate and manage complex machine learning workflows using Step Functions while having the flexibility to provide input parameters for each execution, ensuring efficient and customized MLOps processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f6b9bc-166e-442e-89c9-d43f98e40287",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute the Step Functions workflow with input parameters\n",
    "execution = branching_workflow.execute(\n",
    "    inputs={\n",
    "        \"PreprocessingJobName\": job_name(\"PreprocessingJobName\"),\n",
    "        \"TrainingJobName\": job_name(\"TrainingJobName\"),\n",
    "        # Additional input parameters can be provided here if needed\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682a12c-02bf-4351-98b5-cd34e3911326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the output of the workflow execution (non-blocking, does not wait for completion)\n",
    "execution.get_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ffc9a3-8589-4299-8065-3a2b08dedaae",
   "metadata": {},
   "source": [
    "# Model Inference <a class=\"anchor\" id=\"prediction\"></a>\n",
    "\n",
    "In this section, we perform inference on a deployed machine learning model using SageMaker. The steps involved include creating a predictor, defining input data, creating a payload, making predictions, and printing the results.\n",
    "\n",
    "### Creating a Predictor\n",
    "To perform inference, we first create a SageMaker predictor using the `HuggingFacePredictor` class. The predictor is configured with specific settings, including the SageMaker endpoint name (`endpoint_name`) and the SageMaker session (`sagemaker_session`). The endpoint name indicates which deployed model to use for inference.\n",
    "\n",
    "### Defining Input Data\n",
    "We define the input data for inference as a list of strings. In this case, the input data is a list of text strings that we want to use for making predictions. This data can vary depending on the use case and requirements.\n",
    "\n",
    "### Creating the Payload\n",
    "To send a request for inference, we create a payload, which is formatted as a JSON object. The payload includes two key-value pairs:\n",
    "- `\"inputs\"`: This key holds the input data defined earlier as a list of strings.\n",
    "- `\"parameters\"`: Additional parameters that can be customized based on the inference requirements. In this example, we specify `{\"return_all_scores\": True}` as a parameter.\n",
    "\n",
    "### Making Predictions\n",
    "With the payload ready, we use the `predict` method of the predictor to send the request for inference. The predictor communicates with the specified SageMaker endpoint and returns the inference results.\n",
    "\n",
    "### Printing Predictions\n",
    "Finally, we print the predictions obtained from the model inference. The format and content of the predictions may vary depending on the model and application. In this example, the predictions are printed to the console for review and further processing.\n",
    "\n",
    "This section demonstrates how to perform real-time model inference with SageMaker, making it possible to use machine learning models for various applications, such as natural language processing, image classification, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e17a4-0556-4c5d-8f51-7ca9e43f9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFacePredictor\n",
    "\n",
    "# Create a predictor for your SageMaker endpoint\n",
    "predictor = HuggingFacePredictor(\n",
    "    endpoint_name=\"multi-label-classification--20230922090633\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "# Define the input data as a list of strings\n",
    "inputs = [\"Streamlining Machine Learning Model Deployment with CI/CD and MLOps\"]\n",
    "\n",
    "# Create the payload as a JSON object\n",
    "payload = {\n",
    "    \"inputs\": inputs,\n",
    "    \"parameters\": {\"return_all_scores\": True},\n",
    "}\n",
    "\n",
    "# Make predictions\n",
    "predictions = predictor.predict(payload)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "aws_mlops",
   "language": "python",
   "name": "aws_mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
